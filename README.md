# Moments - AI-Powered Video Highlights

Transform long videos into shareable highlights in seconds using AI-powered scene detection, motion analysis, and audio analysis.

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)](https://fastapi.tiangolo.com/)
[![iOS](https://img.shields.io/badge/iOS-17.0+-black.svg)](https://developer.apple.com/ios/)

---

## ğŸ¯ Overview

Moments is a video highlighting application consisting of:
- **Backend API** (FastAPI/Python) - AI-powered video processing
- **iOS App** (SwiftUI/Swift) - Native mobile experience (coming soon)

**Processing Speed:** 10-15x real-time
**Algorithm:** Scene detection + Motion analysis + Audio analysis + Diversity scoring

---

## ğŸš€ Quick Start

### Backend API

```bash
cd backend
pip install -r requirements.txt
./run.sh
```

Server starts at `http://localhost:8000`

**API Documentation:** http://localhost:8000/docs

---

## ğŸ“± Features

- **Intelligent Scene Detection**: Automatically identifies distinct scenes and segments
- **Motion Analysis**: Detects action moments and camera movements using optical flow
- **Audio Intelligence**: Speech detection, music recognition, excitement level analysis
- **Smart Ranking**: ML-based ranking system to identify the most important moments
- **Automatic Composition**: Creates smooth, watchable highlight reels
- **Background Processing**: Async job queue for handling large videos
- **RESTful API**: Clean API for integration with mobile apps

---

## ğŸ—ï¸ Architecture

### Backend (FastAPI)

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â””â”€â”€ endpoints/
â”‚   â”‚           â””â”€â”€ jobs.py          # Upload, status, download endpoints
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ job.py                   # Job model (SQLAlchemy)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ video_processor.py      # Core AI processing logic
â”‚   â””â”€â”€ main.py                      # FastAPI application
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ uploads/                     # Uploaded videos
â”‚   â””â”€â”€ outputs/                     # Processed highlights
â””â”€â”€ requirements.txt
```

### iOS App (SwiftUI) - Coming Soon

```
MomentsApp/
â”œâ”€â”€ Core/
â”‚   â”œâ”€â”€ Models/                      # Job, VideoConfig
â”‚   â”œâ”€â”€ Services/                    # APIClient, SubscriptionManager
â”‚   â””â”€â”€ Utilities/
â”œâ”€â”€ Features/
â”‚   â”œâ”€â”€ Home/
â”‚   â”œâ”€â”€ Upload/                      # Video picker, upload flow
â”‚   â”œâ”€â”€ Result/                      # Playback, share
â”‚   â””â”€â”€ Subscription/                # Paywall, StoreKit 2
â””â”€â”€ Resources/
```

**Architecture Pattern:** MVVM with @Observable (iOS 17+)

---

## ğŸ¬ API Endpoints

### Upload Video
```http
POST /api/v1/jobs/upload
Content-Type: multipart/form-data

Parameters:
- file: Video file (mp4, mov, avi)
- duration: Target duration in seconds (default: 180)
- min_segment: Minimum segment length (default: 3)
- max_segment: Maximum segment length (default: 10)

Response:
{
  "job_id": "uuid",
  "status": "queued"
}
```

### Check Status
```http
GET /api/v1/jobs/{job_id}/status

Response:
{
  "job_id": "uuid",
  "status": "processing",
  "progress": 45,
  "message": "Analyzing scene 23 of 50"
}
```

### Download Highlight
```http
GET /api/v1/jobs/{job_id}/download

Response: Video file (mp4)
```

---

## ğŸš€ Deployment

### Production (Railway)

1. **Push to GitHub:**
```bash
git add .
git commit -m "Deploy to production"
git push origin main
```

2. **Connect Railway:**
   - Connect GitHub repository
   - Select `backend` directory
   - Railway auto-detects FastAPI

3. **Environment Variables:**
```bash
DATABASE_URL=postgresql://...
STORAGE_TYPE=r2
R2_BUCKET=moments-videos
R2_ACCESS_KEY=...
R2_SECRET_KEY=...
```

**Production URL:** `https://moments-api.up.railway.app`

---

## ğŸ”§ Development

### Local Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
./run.sh
```

### Run Tests

```bash
pytest tests/
```

### API Documentation

Interactive docs: http://localhost:8000/docs

---

## ğŸ’¡ How It Works

1. **Scene Detection**: Analyzes video to find natural scene boundaries using PySceneDetect
2. **Multi-Modal Analysis**:
   - Motion intensity (OpenCV optical flow)
   - Audio characteristics (Whisper speech detection, librosa music analysis)
   - Quality metrics (brightness, contrast, sharpness)
3. **Intelligent Ranking**: ML-based scoring combining motion, audio, and diversity
4. **Smart Selection**: Top-ranked segments selected to fit target duration
5. **Professional Composition**: Segments combined with smooth transitions via FFmpeg

**Processing Speed:** 10-15x real-time (60-minute video â†’ 4-6 minutes processing)

## License

MIT License - See LICENSE file for details

## Contributing

Contributions are welcome! Please feel free to submit pull requests.

## Acknowledgments

- OpenAI Whisper for speech recognition
- PySceneDetect for scene detection
- MoviePy for video processing
- OpenCV for computer vision